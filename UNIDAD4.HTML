<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UNIDAD 4</title>
    <link rel="stylesheet" href="/CLIENTE/unidad4.css">
    <header>
        <nav>
            <ul>
                <li><a href="INICIO.html">Inicio</a></li>
            <li><a href="UNIDAD1.HTML">UNIDAD 1</a></li>
            <li><a href="UNIDAD2.HTML">UNIDAD 2</a></l>
            <li><a href="UNIDAD3.HTML">UNIDAD 3</a></li>
            <li><a href="UNIDAD4.HTML">UNIDAD 4 </a></li>
            <li><a href="https://saltillo.tecnm.mx/">CONOCENOS </a></li>
         </ul>
        </nav>
    </header>
</head>
<body>
    <article>
    <h1>
    4.1 Aspectos Básicos de la Computación Paralela</h1>
    <ul>
        <h1>Computador paralelo</h1>
        <p>Conjunto de elementos de procesos independientes que operan de una forma conjunta para resolver problemas de elevado coste computacional. La computación paralela es una forma de cómputo en la que muchas instrucciones se ejecutan simultáneamente, operando sobre el principio de que problemas grandes, a menudo se pueden dividir en unos más pequeños, que luego son resueltos simultáneamente (en paralelo). Hay varias formas diferentes de computación paralela: paralelismo a nivel de bit, paralelismo a nivel de instrucción, paralelismo de datos y paralelismo de tareas. El paralelismo se ha empleado durante muchos años, sobre todo en la computación de altas prestaciones, pero el interés en ella ha crecido últimamente debido a las limitaciones físicas que impiden el aumento de la frecuencia. Como el consumo de energía y por consiguiente la generación de calor de las computadoras constituye una preocupación en los últimos años, la computación en paralelo se ha convertido en el paradigma dominante en la arquitectura de computadores, principalmente en forma de procesadores multinúcleo. Los programas informáticos paralelos son más difíciles de escribir que los secuenciales, porque la concurrencia introduce nuevos tipos de errores de software, siendo las condiciones de carrera los más comunes. La comunicación y sincronización entre diferentes subtareas son algunos de los mayores obstáculos para obtener un buen rendimiento del programa paralelo. La máxima aceleración posible de un programa como resultado de la paralelización se conoce como la ley de Amdahl.</p>

        <h5>Ley De Amdahl y Ley De Gustafson</h5>
        <p>Ideally, la aceleración a partir de la paralelización es lineal, doblar el número de elementos de procesamiento debe reducir a la mitad el tiempo de ejecución y doblarlo por segunda vez debe nuevamente reducir el tiempo a la mitad. Sin embargo, muy pocos algoritmos paralelos logran una aceleración óptima...</p>

        <h2>Dependencias</h2>
        <p>Entender la dependencia de datos es fundamental en la implementación de algoritmos paralelos...</p>

        <h2>Condiciones de carrera, exclusión mutua, sincronización, y desaceleración paralela</h2>
        <p>Las subtareas en un programa paralelo a menudo son llamadas hilos...</p>

        <h2>Grado de Paralelismo</h2>
        <p>Muy grueso: Programas. Grueso: Subprogramas, tareas...</p>

        <h2>Modelos de Consistencia</h2>
        <p>Los lenguajes de programación en paralelo y computadoras paralelas deben tener un modelo de consistencia de datos también conocido como un modelo de memoria...</p>

        <h2>Taxonomía de Flynn</h2>
        <p>Single Instruction, Single DATA (SISD)...</p>
   

<h2>
Multiple Instruction, Single DATA (MISD)</h2>
<p>
Hay múltiples elementos de procesamiento, en el que cada cual tiene memoria privada del programa, pero se tiene acceso común a una memoria global de información. En cada paso, cada elemento de procesamiento de obtiene la misma información de la memoria y carga una instrucción de la memoria privada del programa. Luego, las instrucciones posiblemente diferentes de cada unidad, son ejecutadas en paralelo, usando la información (idéntica) recibida anteriormente. Este modelo es muy restrictivo y no se ha usado en ningún computador de tipo comercial.
</p>
<h2>
Single Instruction, Multiple DATA (SIMD)
</h2>
<p>
Hay múltiples elementos de procesamiento, en el que cada cual tiene acceso privado a la memoria de información (compartida o distribuida). Sin embargo, hay una sola memoria de programa, desde la cual una unidad de procesamiento especial obtiene y despacha instrucciones. En cada paso, cada unidad de procesamiento obtiene la misma instrucción y carga desde su memoria privada un elemento de información y ejecuta esta instrucción en dicho elemento. Entonces, la instrucción es síncronamente aplicada en paralelo por todos los elementos de proceso a diferentes elementos de información. Para aplicaciones con un grado significante de paralelismo de información, este acercamiento puede ser muy eficiente. Ejemplos pueden ser aplicaciones multimedia y algoritmos de gráficos de computadora.
</p>
<h4>
Multiple Instruction, Multiple DATA (MIMD)</h4>
Hay múltiples unidades de procesamiento, en la cual cada una tiene tanto instrucciones como información separada. Cada elemento ejecuta una instrucción distinta en un elemento de información distinto. Los elementos de proceso trabajan asíncronamente. Los clusters son ejemplo son ejemplos del modelo MIMD.
</ul>
</p> </article>
<h1>
4.2 Tipos de Computación Paralela
</h1>
<ul>
<p>
    <h2>1. Paralelismo a nivel de bit</h2>
    <p>Desde la adopción de la integración a gran escala (VLSI) como tecnología de fabricación de chips de computadora en la década de 1970 hasta alrededor de 1986, la aceleración en la arquitectura de computadoras se lograba en gran medida duplicando el tamaño de la palabra en la computadora, la cantidad de información que el procesador puede manejar por ciclo.</p>
    <p>Los microprocesadores históricamente han ido desde 4 bits hasta 8, luego 16 y 32 bits; esta tendencia finalizó con la introducción de procesadores de 64 bits, que ha sido un estándar en la computación de propósito general durante la última década.</p>
  
    <h2>2. Paralelismo a nivel de instrucción</h2>
    <p>Los procesadores modernos tienen 'pipeline' de instrucciones de múltiples etapas. Cada etapa corresponde a una acción diferente que el procesador realiza en la instrucción correspondiente; un procesador con un pipeline de N etapas puede tener hasta n instrucciones diferentes en diferentes etapas de finalización. Por ejemplo, un procesador RISC típico tiene cinco etapas: pedir instrucción, decodificar, ejecutar, acceso a la memoria y escritura. El procesador Pentium 4 tenía un pipeline de 35 etapas.</p>
    <p>Además del paralelismo a nivel de instrucción del pipelining, algunos procesadores pueden ejecutar más de una instrucción a la vez. Estos son conocidos como procesadores superescalares. Las instrucciones pueden agruparse sólo si no hay dependencia de datos entre ellas. Dos de las técnicas más comunes para implementar la ejecución fuera de orden y la paralelización a nivel de instrucción son el scoreboarding y el algoritmo de Tomasulo, que hace uso del renombre de registros.</p>
  
    <h2>Paralelismo de datos</h2>
    <p>El paralelismo de datos se encuentra en programas con ciclos, distribuyendo los datos entre los nodos computacionales para procesamiento paralelo. Muchas aplicaciones científicas e ingenieriles muestran este paralelismo. Las dependencias de terminación de ciclo evitan la paralelización de ciclos al depender una iteración de la salida de una o más iteraciones anteriores.</p>
  
    <h2>Paralelismo de tareas</h2>
    <p>Es un paradigma de la programación concurrente que asigna distintas tareas a cada procesador en un sistema de cómputo. Cada procesador efectúa su propia secuencia de operaciones. Generalmente se representa mediante un grafo de tareas, subdividido en subgrafos asignados a diferentes procesadores.</p>

</p></ul>
<h2>
4.2.1 Clasificación</h2>
<ul>
<p>
Las computadoras paralelas se pueden clasificar de acuerdo con el nivel en el que el hardware soporta paralelismo. Esta clasificación es análoga a la distancia entre los nodos básicos de cómputo.

Computación Multinúcleo:Un procesador multinúcleo es un procesador que incluye múltiples unidades de ejecución (núcleos) en el mismo chip.
Multiprocesamiento Simétrico:Un multiprocesador simétrico (SMP) es un sistema computacional con múltiples procesadores idénticos que comparten memoria y se conectan a través de un bus.
Computación en Clúster:Un clúster es un grupo de ordenadores débilmente acoplados que trabajan en estrecha colaboración, de modo que en algunos aspectos pueden considerarse como un solo equipo.
Procesamiento Paralelo Masivo:Tienden a ser más grandes que los clústeres, con «mucho más» de 100 procesadores.
Procesadores Vectoriales:Pueden ejecutar la misma instrucción en grandes conjuntos de datos. Tienen operaciones de alto nivel que trabajan sobre arreglos lineales de números o vectores.
Computacion Distribuida:La computación distribuida es la forma más distribuida de la computación paralela. Se hace uso de ordenadores que se comunican a través de la Internet para trabajar en un problema dado.
Computadoras Paralelas Especializadas:Dentro de la computación paralela, existen dispositivos paralelos especializados que generan interés. Aunque no son específicos para un dominio, tienden a ser aplicables sólo a unas pocas clases de problemas paralelos.
Circuitos integrados de aplicación específica:Debido a que un ASIC (por definición) es específico para una aplicación dada, puede ser completamente optimizado para esa aplicación.
</p></ul>
<h2>4.2.2 Arquitectura de computadores secuenciales</h2>
<ul>
<p>
A diferencia de los sistemas combinacionales, en los sistemas secuenciales, los valores de las salidas, en un momento dado, no dependen exclusivamente de los valores de las entradas en dicho momento, sino también dependen del estado anterior o estado interno.


El sistema secuencial requiere de la utilización de un dispositivo de memoria que pueda almacenar la historia pasada de sus entradas (denominadas variables de estado) y le permita mantener su estado durante algún tiempo, estos dispositivos de memoria pueden ser sencillos como un simple retardador o celdas de memoria de tipo DRAM, SRAM o multivibradores biestables también conocido como Flip-Flop.


Tipos de sistemas secuenciales
En este tipo de circuitos entra un factor que no se había considerado en los circuitos combinacionales, dicho factor es el tiempo, según como manejan el tiempo se pueden clasificar en: circuitos secuenciales síncronos y circuitos secuenciales asíncronos.

Circuitos secuenciales asíncronos
En circuitos secuenciales asíncronos los cambios de estados ocurren al ritmo natural asociado a las compuertas lógicas utilizadas en su implementación, lo que produce retardos en cascadas entre los biestables del circuito, es decir no utilizan elementos especiales de memoria, lo que puede ocasionar algunos problemas de funcionamiento, ya que estos retardos naturales no están bajo el control del diseñador y además no son idénticos en cada compuerta lógica.

Circuitos secuenciales síncronos
Los circuitos secuenciales síncronos solo permiten un cambio de estado en los instantes marcados o autorizados por una señal de sincronismo de tipo oscilatorio denominada reloj (cristal o circuito capaz de producir una serie de pulsos regulares en el tiempo), lo que soluciona los problemas que tienen los circuitos asíncronos originados por cambios de estado no uniformes dentro del sistema o circuito.
</p></ul>
<h2>
4.2.3 Organización de direcciones de memoria </h2>
<ul>
<p>
La memoria principal en un ordenador en paralelo puede ser compartida —compartida entre todos los elementos de procesamiento en un único espacio de direcciones—, o distribuida —cada elemento de procesamiento tiene su propio espacio local de direcciones—.El término memoria distribuida se refiere al hecho de que la memoria se distribuye lógicamente, pero a menudo implica que también se distribuyen físicamente.


Los accesos a la memoria local suelen ser más rápidos que los accesos a memoria no local. Las arquitecturas de ordenador en las que cada elemento de la memoria principal se puede acceder con igual latencia y ancho de banda son conocidas como arquitecturas de acceso uniforme a memoria (UMA).


Un sistema que no tiene esta propiedad se conoce como arquitectura de acceso a memoria no uniforme (NUMA). Los sistemas de memoria distribuidos tienen acceso no uniforme a la memoria.

</p></ul>
<h1>
4.3 Sistema de memoria de multiprocesadores(Comparaciones)</h1>
<ul>
<p>
Todos los procesadores acceden a una memoria común.
La comunicación entre procesadores se hace a través de la memoria.
Se necesitan primitivas de sincronismo para asegurar el intercambio de datos.

Estructura de los multiprocesadores de memoria compartida
La mayoría de los multiprocesadores comerciales son del tipo UMA (Uniform Memory Access): todos los procesadores tienen igual tiempo de acceso a la memoria compartida. En la arquitectura UMA los procesadores se conectan a la memoria a través de un bus, una red multietapa o un conmutador de barras cruzadas (crossbar crossbar) y disponen de su propia memoria caché. Los procesadores tipo NUMA (Non Uniform Memory Access) presentan tiempos de acceso a la memoria compartida que dependen de la ubicación del elemento de proceso y la memoria.
</p></ul>
<h2>

4.3.1 Fuentes de interconexión dinámica</h2>
<ul>
<p>
Medio Compartido
Conexion por bus compartido
Es la organización más común en los computadores personales y servidores. El bus consta de líneas de dirección, datos y control para implementar:

El protocolo de transferencias de datos con la memoria.
El arbitraje del acceso al bus cuando más de un procesador compite por utilizarlo.

Los procesadores utilizan cachés locales para:
Reducir el tiempo medio de acceso a memoria, como en un monoprocesador.
Disminuir la utilización del bus compartido.


Protocolos de transferencia de ciclo partido
La operación de lectura se divide en dos transacciones no continuas de acceso al bus. La primera es de petición de lectura que realiza el máster (procesador) sobre el slave (memoria). Una vez realizada la petición el máster abandona el bus. Cuando el slave dispone del dato leído, inicia un ciclo de bus actuando como máster para enviar el dato al antiguo máster, que ahora actúa como slave.

Protocolo de arbitraje distribuido
La responsabilidad del arbitraje se distribuye por los diferentes procesadores conectados al bus.

</p></ul>
<h2>
4.3.1.2 Redes Conmutadas
</h2>
<ul>
<p>
Conexión por conmutadores crossbar.
Cada procesador (Pi) y cada módulo de memoria (Mi) tienen su propio bus. Existe un conmutador (S) en los puntos de intersección que permite conectar un bus de memoria con un bus de procesador. Para evitar conflictos cuando más de un procesador pretende acceder al mismo módulo de memoria se establece un orden de prioridad. Se trata de una red sin bloqueo con una conectividad completa pero de alta complejidad.
</p></ul>
<p><ul>
Conexión por red multietapa
Representan una alternativa intermedia de conexión entre el bus y el crossbar.
Es de menor complejidad que el crossbar pero mayor que el bus simple.
La conectividad es mayor que la del bus simple pero menor que la del crossbar.
Se compone de varias etapas alternativas de conmutadores simples y redes de interconexión.
</p></ul>
<h1>

4.4 Sistema de memoria de multiprocesadores(Distributiva)
</h1>

<ul><p>
Cada procesador tiene su propia memoria y la comunicación se realiza por intercambio explícito de mensajes a través de una red.



Ventajas
•El número de nodos puede ir desde algunas decenas hasta varios miles (o más).
•El número de canales físicos entre nodos suele oscilar entre cuatro y ocho.
•Esta arquitectura es directamente escalable y presenta un bajo coste para sistemas grandes.
•La arquitectura de paso de mensajes tiene ventajas sobre la de memoria compartida cuando el número de procesadores es grande.

Desventajas
•Se necesitan técnicas de sincronización para acceder a las variables compartidas.
•La contención en la memoria puede reducir significativamente la velocidad.
•Todos los procesadores en el sistema de multiprocesamiento comparten la memoria principal.
•No son fácilmente escalables a un gran número de procesadores.

</p></ul>
<h2>
4.4.1 Red de interconexión estática</h2>
Los multicomputadores utilizan redes estáticas con enlaces directos entre nodos. Cuando un nodo recibe un mensaje lo procesa si viene dirigido a dicho nodo. Si el mensaje no va dirigido al nodo receptor lo reenvía a otro por alguno de sus enlaces de salida siguiendo un protocolo de encaminamiento.

<p>
    <ul>
Propiedades más significativas:
TOPOLOGÍA DE LA RED
Determina el patrón de interconexión entre nodos.
DIÁMETRO DE LA RED
Distancia máxima de los caminos más cortos entre dos nodos de la red.
LATENCIA
Retardo de tiempo en el peor caso para un mensaje transferido a través de la red.
ANCHO DE BANDA
Transferencia máxima de datos en Mbytes/segundo.
ESCALABILIDAD
Posibilidad de expansión modular de la red.
GRADO DE UN NODO
Número de enlaces o canales que inciden en el nodo.
ALGORITMO DE ENCAMINAMIENTO
Determina el camino que debe seguir un mensaje desde el nodo emisor al nodo receptor.
</ul>
</p>
<h1>
4.5 Casos de Estudio
</h1>
<p>
Por numerosos motivos, el procesamiento distribuido se ha convertido en un área de gran importancia e interés dentro de la ciencia de la computación, produciendo profundas transformaciones en las líneas de investigación y desarrollo.


Interesa realizar investigación en la especificación, transformación, optimización y evaluación de algoritmos distribuidos y paralelos. Esto incluye el diseño y desarrollo de sistemas paralelos, la transformación de algoritmos secuenciales en paralelos, y las métricas de evaluación de performance sobre distintas plataformas de soporte (hardware y software). Más allá de las mejoras constantes en las arquitecturas físicas de soporte, uno de los mayores desafíos se centra en cómo aprovechar al máximo la potencia de las mismas.

<ul>
    <li>Paralelización de algoritmos secuenciales. Diseño y optimización de algoritmos.</li>
    <li>Arquitecturas multicore y multithreading en multicore.</li>
    <li>Modelos de representación y predicción de performance de algoritmos paralelos.</li>
    <li>Mapping y scheduling de aplicaciones paralelas sobre distintas arquitecturas multiprocesador.</li>
    <li>Métricas del paralelismo. Speedup, eficiencia, rendimiento, granularidad, superlinealidad.</li>
    <li>Balance de carga estático y dinámico. Técnicas de balanceo de carga.</li>
    <li>Análisis de los problemas de migración y asignación óptima de procesos y datos a procesadores.</li>
    <li>Patrones de diseño de algoritmos paralelos.</li>
    <li>Escalabilidad de algoritmos paralelos en arquitecturas multiprocesador distribuidas.</li>
    <li>Implementación de soluciones sobre diferentes modelos de arquitectura homogéneas y heterogéneas.</li>
    <li>Laboratorios remotos para el acceso transparente a recursos de cómputo paralelo.</li>
  </ul>
<ul>
Algunas Implementaciones con procesamiento paralelo.
Nvidia
Capa física (physical layer):
GPU PhysX
CPU PhysX
Capa de gráficos (graphics layer):
GPU DirectX Windows
</ul>
<ul>
Intel
Capa física (physical layer):
No GPU PhysX
CPU Havok
Capa de gráficos (graphics layer):
GPU DirectX Windows
</ul>
<ul>

AMD
Capa física (physical layer):
No GPU PhysX
CPU Havok
Capa de gráficos (graphics layer):
GPU DirectX Windows
</ul>
</p>
</body>
</article>
</html>